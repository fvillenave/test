{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fvillenave/test/blob/main/Copie_de_Day2_teacher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Information Retrieval\n",
        "## Introduction to search engines\n",
        "\n",
        "### DAY 2: Teacher version\n",
        "### Implementing a search engine\n",
        "\n",
        "The goal of this second session is to implement a first architecture of a search engine on the previously introduced dataset (stackexchange-datascience). If you missed the first session or if you did not saved the dataset, please reload the first session's notebook to download it. \n",
        "\n",
        "If you need some ifnormation about the dataset, it should be available here : https://archive.org/details/stackexchange\n",
        "\n",
        "The notebook is divided into several steps:\n",
        "-\tImplement the indexation\n",
        "-\tImplement the search method\n",
        "-\tDefine a ranking strategy and implement it\n",
        "-\tSuggest some improvements of the search engine\n",
        "\n"
      ],
      "metadata": {
        "id": "Fiy0xFlZLomY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialisation"
      ],
      "metadata": {
        "id": "QH_WrILaSIJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ttable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H819R7iJF_y",
        "outputId": "1027de9f-b795-4df0-f00c-016e5cc83576"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ttable\n",
            "  Downloading ttable-0.6.4.tar.gz (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.3/122.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ttable\n",
            "  Building wheel for ttable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ttable: filename=ttable-0.6.4-cp310-cp310-linux_x86_64.whl size=212629 sha256=1a3455139acffe92b08f9d6f6d0e50d0a9473a7046ca0e0a46f3e4b1e3079d1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/8d/56/f2572fdbf1ef1f8a947d7ff25ce18d9373d8e02a68f9ac8de6\n",
            "Successfully built ttable\n",
            "Installing collected packages: ttable\n",
            "Successfully installed ttable-0.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tt import BooleanExpression\n",
        "from itertools import product"
      ],
      "metadata": {
        "id": "lI2VFiG1SJmJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only if you use Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YySiGfQ1SNwT",
        "outputId": "7f38562f-51a2-40bc-e0da-e8dd52445a34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO:\n",
        "DATA_PATH = '' \n",
        "\n",
        "# CORR:\n",
        "DATA_PATH = '/content/drive/MyDrive/TP Centrale/data'"
      ],
      "metadata": {
        "id": "0rq6fLsSSPUn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement the indexation\n",
        "As you might already know, for a search engine to work properly an index of the documents must be created. Here we will keep it in python, and try to use only common libraries to keep it simple.\n",
        "\n",
        "Once created, the index will be used to match the query with the documents. As a result, there are several ways to build an index, using statistical, boolean, semantic indexation...\n",
        "\n",
        "First of, let's make a naive one that will consist in breaking down each document into a set of the words it contains."
      ],
      "metadata": {
        "id": "PzqYFBxYAJN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_words(text:str)->list:\n",
        "  # TODO\n",
        "\n",
        "  # CORR:\n",
        "  return list(set(text.split()))"
      ],
      "metadata": {
        "id": "lOClVNL5_abL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# test\n",
        "s = \"The cat is sat on the mat. The dog is laid on the mat.\"\n",
        "assert extract_words(s).sort()==[\"The\",\"cat\",\"is\",\"sat\",\"on\",\"the\",\"mat.\",\"dog\",\"laid\"].sort()"
      ],
      "metadata": {
        "id": "QwVgveW6CIAz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you may notice, there are several problems with the previous implementation. First, \"The\" and \"the\" aren't considered the same, the \".\" is kept at the the end of \"mat.\" as any other punctuation character... \n",
        "\n",
        "Re-implement this function with some basic preprocessing to avoid these issues."
      ],
      "metadata": {
        "id": "qTFNPmNJC75C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_words(text:str)->list:\n",
        "  #TODO\n",
        "\n",
        "  #CORR\n",
        "  return list(set(re.sub(r'[^\\w\\s]', '', text.lower()).split()))"
      ],
      "metadata": {
        "id": "eg9aRYX-CTTH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "assert extract_words(s).sort()==[\"the\",\"cat\",\"is\",\"sat\",\"on\",\"mat\",\"dog\",\"laid\"].sort()"
      ],
      "metadata": {
        "id": "wnTSVCA1Fd1q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you sould be able to create your index table. For now we will just make a dataframe with two columns: [raw_text, words]."
      ],
      "metadata": {
        "id": "TVQq7QZKF7mM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def index_docs(docs:list[str])->pd.DataFrame:\n",
        "  df = pd.DataFrame({\"raw_docs\":docs})\n",
        "  df['words'] = df['raw_docs'].apply(extract_words)\n",
        "  return df"
      ],
      "metadata": {
        "id": "XLO7naGaF0LP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "\n",
        "L = [s, \"Hello World!\", \"Goodbye\", \"How are you?\"]\n",
        "\n",
        "index_docs(L)"
      ],
      "metadata": {
        "id": "IpK3zlftGw_w",
        "outputId": "c961af9f-d2b0-4417-93f6-9f9702def2ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            raw_docs  \\\n",
              "0  The cat is sat on the mat. The dog is laid on ...   \n",
              "1                                       Hello World!   \n",
              "2                                            Goodbye   \n",
              "3                                       How are you?   \n",
              "\n",
              "                                     words  \n",
              "0  [on, cat, laid, the, sat, dog, mat, is]  \n",
              "1                           [world, hello]  \n",
              "2                                [goodbye]  \n",
              "3                          [are, you, how]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ebfb8c0d-6751-490c-8c9f-ed50fbf254a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>raw_docs</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The cat is sat on the mat. The dog is laid on ...</td>\n",
              "      <td>[on, cat, laid, the, sat, dog, mat, is]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hello World!</td>\n",
              "      <td>[world, hello]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Goodbye</td>\n",
              "      <td>[goodbye]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How are you?</td>\n",
              "      <td>[are, you, how]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebfb8c0d-6751-490c-8c9f-ed50fbf254a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ebfb8c0d-6751-490c-8c9f-ed50fbf254a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ebfb8c0d-6751-490c-8c9f-ed50fbf254a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's try it on the dataset:"
      ],
      "metadata": {
        "id": "70w-UfpsHktY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Only if you use Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# TODO:\n",
        "DATA_PATH = '' \n",
        "\n",
        "# CORR:\n",
        "DATA_PATH = '/content/drive/MyDrive/TP Centrale/data'"
      ],
      "metadata": {
        "id": "kqgYWivEKHuU",
        "outputId": "07ebb271-2c79-4222-c183-6de2803d4aeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "posts = pd.read_xml(os.path.join(DATA_PATH, 'Posts.xml'), parser=\"etree\", encoding=\"utf8\")\n",
        "posts"
      ],
      "metadata": {
        "id": "46pO8FszG_4s",
        "outputId": "93ac398b-3342-4350-a5c5-6f780b24fc76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Id  PostTypeId             CreationDate  Score  ViewCount  \\\n",
              "0           5           1  2014-05-13T23:58:30.457      9      898.0   \n",
              "1           7           1  2014-05-14T00:11:06.457      4      478.0   \n",
              "2           9           2  2014-05-14T00:36:31.077      5        NaN   \n",
              "3          10           2  2014-05-14T00:53:43.273     13        NaN   \n",
              "4          14           1  2014-05-14T01:25:59.677     26     1901.0   \n",
              "...       ...         ...                      ...    ...        ...   \n",
              "75722  119962           1  2023-03-04T20:06:06.820      0        8.0   \n",
              "75723  119963           1  2023-03-04T20:12:19.677      0       10.0   \n",
              "75724  119964           1  2023-03-05T00:14:12.597      0        7.0   \n",
              "75725  119965           1  2023-03-05T00:43:12.213      0        5.0   \n",
              "75726  119966           1  2023-03-05T03:10:27.593      0        2.0   \n",
              "\n",
              "                                                    Body  OwnerUserId  \\\n",
              "0      <p>I've always been interested in machine lear...          5.0   \n",
              "1      <p>As a researcher and instructor, I'm looking...         36.0   \n",
              "2      <p>Not sure if this fits the scope of this SE,...         51.0   \n",
              "3      <p>One book that's freely available is \"The El...         22.0   \n",
              "4      <p>I am sure data science as will be discussed...         66.0   \n",
              "...                                                  ...          ...   \n",
              "75722  <p>I am implementing a neural network of arbit...     147597.0   \n",
              "75723  <p>I am using KNN for a regression task</p>\\n<...     147598.0   \n",
              "75724  <p>I have developed a small encoding algorithm...      44581.0   \n",
              "75725  <p>To my understanding, optimizing a model wit...      84437.0   \n",
              "75726  <p>I'm working with a dataset of cars, contain...     147605.0   \n",
              "\n",
              "              LastActivityDate  \\\n",
              "0      2014-05-14T00:36:31.077   \n",
              "1      2014-05-16T13:45:00.237   \n",
              "2      2014-05-14T00:36:31.077   \n",
              "3      2014-05-14T00:53:43.273   \n",
              "4      2020-08-16T13:01:33.543   \n",
              "...                        ...   \n",
              "75722  2023-03-04T20:22:12.523   \n",
              "75723  2023-03-04T20:12:19.677   \n",
              "75724  2023-03-05T00:14:12.597   \n",
              "75725  2023-03-05T00:43:12.213   \n",
              "75726  2023-03-05T03:10:27.593   \n",
              "\n",
              "                                                   Title  \\\n",
              "0      How can I do simple machine learning without h...   \n",
              "1      What open-source books (or other materials) pr...   \n",
              "2                                                   None   \n",
              "3                                                   None   \n",
              "4               Is Data Science the Same as Data Mining?   \n",
              "...                                                  ...   \n",
              "75722  Back Propagation on arbitrary depth network wi...   \n",
              "75723                        Evaluation parameter in knn   \n",
              "75724  Can I use zero-padded input and output layers ...   \n",
              "75725  Why does cross validation and hyperparameter t...   \n",
              "75726                High metrics value (MAE, MSE, RMSE)   \n",
              "\n",
              "                                                    Tags  ...  \\\n",
              "0                                     <machine-learning>  ...   \n",
              "1                               <education><open-source>  ...   \n",
              "2                                                   None  ...   \n",
              "3                                                   None  ...   \n",
              "4                             <data-mining><definitions>  ...   \n",
              "...                                                  ...  ...   \n",
              "75722                  <neural-network><backpropagation>  ...   \n",
              "75723                                 <regression><k-nn>  ...   \n",
              "75724      <deep-learning><convolutional-neural-network>  ...   \n",
              "75725          <cross-validation><hyperparameter-tuning>  ...   \n",
              "75726  <python><pandas><machine-learning-model><linea...  ...   \n",
              "\n",
              "                    ClosedDate  ContentLicense AcceptedAnswerId  \\\n",
              "0      2014-05-14T14:40:25.950    CC BY-SA 3.0              NaN   \n",
              "1      2014-05-14T08:40:54.950    CC BY-SA 3.0             10.0   \n",
              "2                         None    CC BY-SA 3.0              NaN   \n",
              "3                         None    CC BY-SA 3.0              NaN   \n",
              "4                         None    CC BY-SA 3.0             29.0   \n",
              "...                        ...             ...              ...   \n",
              "75722                     None    CC BY-SA 4.0              NaN   \n",
              "75723                     None    CC BY-SA 4.0              NaN   \n",
              "75724                     None    CC BY-SA 4.0              NaN   \n",
              "75725                     None    CC BY-SA 4.0              NaN   \n",
              "75726                     None    CC BY-SA 4.0              NaN   \n",
              "\n",
              "      LastEditorUserId             LastEditDate  ParentId OwnerDisplayName  \\\n",
              "0                  NaN                     None       NaN             None   \n",
              "1                 97.0  2014-05-16T13:45:00.237       NaN             None   \n",
              "2                  NaN                     None       5.0             None   \n",
              "3                  NaN                     None       7.0             None   \n",
              "4                322.0  2014-06-17T16:17:20.473       NaN             None   \n",
              "...                ...                      ...       ...              ...   \n",
              "75722         147597.0  2023-03-04T20:22:12.523       NaN             None   \n",
              "75723              NaN                     None       NaN             None   \n",
              "75724              NaN                     None       NaN             None   \n",
              "75725              NaN                     None       NaN             None   \n",
              "75726              NaN                     None       NaN             None   \n",
              "\n",
              "       CommunityOwnedDate LastEditorDisplayName FavoriteCount  \n",
              "0                    None                  None           NaN  \n",
              "1                    None                  None           NaN  \n",
              "2                    None                  None           NaN  \n",
              "3                    None                  None           NaN  \n",
              "4                    None                  None           NaN  \n",
              "...                   ...                   ...           ...  \n",
              "75722                None                  None           NaN  \n",
              "75723                None                  None           NaN  \n",
              "75724                None                  None           NaN  \n",
              "75725                None                  None           NaN  \n",
              "75726                None                  None           NaN  \n",
              "\n",
              "[75727 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4fda0f9-4f10-4159-bc82-fac4cdcd5dda\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>PostTypeId</th>\n",
              "      <th>CreationDate</th>\n",
              "      <th>Score</th>\n",
              "      <th>ViewCount</th>\n",
              "      <th>Body</th>\n",
              "      <th>OwnerUserId</th>\n",
              "      <th>LastActivityDate</th>\n",
              "      <th>Title</th>\n",
              "      <th>Tags</th>\n",
              "      <th>...</th>\n",
              "      <th>ClosedDate</th>\n",
              "      <th>ContentLicense</th>\n",
              "      <th>AcceptedAnswerId</th>\n",
              "      <th>LastEditorUserId</th>\n",
              "      <th>LastEditDate</th>\n",
              "      <th>ParentId</th>\n",
              "      <th>OwnerDisplayName</th>\n",
              "      <th>CommunityOwnedDate</th>\n",
              "      <th>LastEditorDisplayName</th>\n",
              "      <th>FavoriteCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-05-13T23:58:30.457</td>\n",
              "      <td>9</td>\n",
              "      <td>898.0</td>\n",
              "      <td>&lt;p&gt;I've always been interested in machine lear...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2014-05-14T00:36:31.077</td>\n",
              "      <td>How can I do simple machine learning without h...</td>\n",
              "      <td>&lt;machine-learning&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>2014-05-14T14:40:25.950</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-05-14T00:11:06.457</td>\n",
              "      <td>4</td>\n",
              "      <td>478.0</td>\n",
              "      <td>&lt;p&gt;As a researcher and instructor, I'm looking...</td>\n",
              "      <td>36.0</td>\n",
              "      <td>2014-05-16T13:45:00.237</td>\n",
              "      <td>What open-source books (or other materials) pr...</td>\n",
              "      <td>&lt;education&gt;&lt;open-source&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>2014-05-14T08:40:54.950</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>2014-05-16T13:45:00.237</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>2014-05-14T00:36:31.077</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;p&gt;Not sure if this fits the scope of this SE,...</td>\n",
              "      <td>51.0</td>\n",
              "      <td>2014-05-14T00:36:31.077</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>5.0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>2014-05-14T00:53:43.273</td>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;p&gt;One book that's freely available is \"The El...</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2014-05-14T00:53:43.273</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>7.0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-05-14T01:25:59.677</td>\n",
              "      <td>26</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>&lt;p&gt;I am sure data science as will be discussed...</td>\n",
              "      <td>66.0</td>\n",
              "      <td>2020-08-16T13:01:33.543</td>\n",
              "      <td>Is Data Science the Same as Data Mining?</td>\n",
              "      <td>&lt;data-mining&gt;&lt;definitions&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>CC BY-SA 3.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>2014-06-17T16:17:20.473</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75722</th>\n",
              "      <td>119962</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-04T20:06:06.820</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>&lt;p&gt;I am implementing a neural network of arbit...</td>\n",
              "      <td>147597.0</td>\n",
              "      <td>2023-03-04T20:22:12.523</td>\n",
              "      <td>Back Propagation on arbitrary depth network wi...</td>\n",
              "      <td>&lt;neural-network&gt;&lt;backpropagation&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>147597.0</td>\n",
              "      <td>2023-03-04T20:22:12.523</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75723</th>\n",
              "      <td>119963</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-04T20:12:19.677</td>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>&lt;p&gt;I am using KNN for a regression task&lt;/p&gt;\\n&lt;...</td>\n",
              "      <td>147598.0</td>\n",
              "      <td>2023-03-04T20:12:19.677</td>\n",
              "      <td>Evaluation parameter in knn</td>\n",
              "      <td>&lt;regression&gt;&lt;k-nn&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75724</th>\n",
              "      <td>119964</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-05T00:14:12.597</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>&lt;p&gt;I have developed a small encoding algorithm...</td>\n",
              "      <td>44581.0</td>\n",
              "      <td>2023-03-05T00:14:12.597</td>\n",
              "      <td>Can I use zero-padded input and output layers ...</td>\n",
              "      <td>&lt;deep-learning&gt;&lt;convolutional-neural-network&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75725</th>\n",
              "      <td>119965</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-05T00:43:12.213</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>&lt;p&gt;To my understanding, optimizing a model wit...</td>\n",
              "      <td>84437.0</td>\n",
              "      <td>2023-03-05T00:43:12.213</td>\n",
              "      <td>Why does cross validation and hyperparameter t...</td>\n",
              "      <td>&lt;cross-validation&gt;&lt;hyperparameter-tuning&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75726</th>\n",
              "      <td>119966</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-03-05T03:10:27.593</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>&lt;p&gt;I'm working with a dataset of cars, contain...</td>\n",
              "      <td>147605.0</td>\n",
              "      <td>2023-03-05T03:10:27.593</td>\n",
              "      <td>High metrics value (MAE, MSE, RMSE)</td>\n",
              "      <td>&lt;python&gt;&lt;pandas&gt;&lt;machine-learning-model&gt;&lt;linea...</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75727 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4fda0f9-4f10-4159-bc82-fac4cdcd5dda')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4fda0f9-4f10-4159-bc82-fac4cdcd5dda button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4fda0f9-4f10-4159-bc82-fac4cdcd5dda');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our first version of the indexation mechanism, we will simply use the \"body\" of the posts. To have a better search engine, the title and other metadata aswell could be used aswell. Finally, not all the XML files have a \"body\" feature, so for the search engine to retrieve information from any of the files you will need to implement another way to index.\n",
        "\n",
        "But first, let's start with \"body\". There is more to preprocess than before, indeed, there are html tags such as \"<p>\" for instance. They are not useful for us, because users won't use them in their queries. So we first need to remove them."
      ],
      "metadata": {
        "id": "DcaGAngHLK4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_tags(text:str)->str:\n",
        "  pattern_html = re.compile('<.*?>')\n",
        "  clean_post = pattern_html.sub('', text)\n",
        "\n",
        "  # remove other things\n",
        "\n",
        "  clean_post = clean_post.replace('\\n', '').replace('\\t', '')\n",
        "  return clean_post"
      ],
      "metadata": {
        "id": "Et-7VlXyKuaf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "remove_tags('<p>Hello World!\\nI am making a search engine.<p>')"
      ],
      "metadata": {
        "id": "JQAW9pi9MkyZ",
        "outputId": "0348cf8d-43b4-4369-9b75-ba8d1641d6d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello World!I am making a search engine.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_posts = posts[['Id','Body']]\n",
        "clean_posts['Clean Body'] = clean_posts['Body'].fillna('').apply(remove_tags)\n",
        "clean_posts"
      ],
      "metadata": {
        "id": "lDiFEsPtMszw",
        "outputId": "89c3ff34-fe31-4137-e804-510ebd870a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-2f3e0e9b59ce>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clean_posts['Clean Body'] = clean_posts['Body'].fillna('').apply(remove_tags)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Id                                               Body  \\\n",
              "0           5  <p>I've always been interested in machine lear...   \n",
              "1           7  <p>As a researcher and instructor, I'm looking...   \n",
              "2           9  <p>Not sure if this fits the scope of this SE,...   \n",
              "3          10  <p>One book that's freely available is \"The El...   \n",
              "4          14  <p>I am sure data science as will be discussed...   \n",
              "...       ...                                                ...   \n",
              "75722  119962  <p>I am implementing a neural network of arbit...   \n",
              "75723  119963  <p>I am using KNN for a regression task</p>\\n<...   \n",
              "75724  119964  <p>I have developed a small encoding algorithm...   \n",
              "75725  119965  <p>To my understanding, optimizing a model wit...   \n",
              "75726  119966  <p>I'm working with a dataset of cars, contain...   \n",
              "\n",
              "                                              Clean Body  \n",
              "0      I've always been interested in machine learnin...  \n",
              "1      As a researcher and instructor, I'm looking fo...  \n",
              "2      Not sure if this fits the scope of this SE, bu...  \n",
              "3      One book that's freely available is \"The Eleme...  \n",
              "4      I am sure data science as will be discussed in...  \n",
              "...                                                  ...  \n",
              "75722  I am implementing a neural network of arbitrar...  \n",
              "75723  I am using KNN for a regression taskIt's like ...  \n",
              "75724  I have developed a small encoding algorithm th...  \n",
              "75725  To my understanding, optimizing a model with k...  \n",
              "75726  I'm working with a dataset of cars, containing...  \n",
              "\n",
              "[75727 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a398f4b4-d86a-42f3-9baf-6da160a19d41\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Body</th>\n",
              "      <th>Clean Body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>&lt;p&gt;I've always been interested in machine lear...</td>\n",
              "      <td>I've always been interested in machine learnin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>&lt;p&gt;As a researcher and instructor, I'm looking...</td>\n",
              "      <td>As a researcher and instructor, I'm looking fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>&lt;p&gt;Not sure if this fits the scope of this SE,...</td>\n",
              "      <td>Not sure if this fits the scope of this SE, bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>&lt;p&gt;One book that's freely available is \"The El...</td>\n",
              "      <td>One book that's freely available is \"The Eleme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>&lt;p&gt;I am sure data science as will be discussed...</td>\n",
              "      <td>I am sure data science as will be discussed in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75722</th>\n",
              "      <td>119962</td>\n",
              "      <td>&lt;p&gt;I am implementing a neural network of arbit...</td>\n",
              "      <td>I am implementing a neural network of arbitrar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75723</th>\n",
              "      <td>119963</td>\n",
              "      <td>&lt;p&gt;I am using KNN for a regression task&lt;/p&gt;\\n&lt;...</td>\n",
              "      <td>I am using KNN for a regression taskIt's like ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75724</th>\n",
              "      <td>119964</td>\n",
              "      <td>&lt;p&gt;I have developed a small encoding algorithm...</td>\n",
              "      <td>I have developed a small encoding algorithm th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75725</th>\n",
              "      <td>119965</td>\n",
              "      <td>&lt;p&gt;To my understanding, optimizing a model wit...</td>\n",
              "      <td>To my understanding, optimizing a model with k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75726</th>\n",
              "      <td>119966</td>\n",
              "      <td>&lt;p&gt;I'm working with a dataset of cars, contain...</td>\n",
              "      <td>I'm working with a dataset of cars, containing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75727 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a398f4b4-d86a-42f3-9baf-6da160a19d41')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a398f4b4-d86a-42f3-9baf-6da160a19d41 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a398f4b4-d86a-42f3-9baf-6da160a19d41');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_posts['words'] = clean_posts['Clean Body'].apply(extract_words)\n",
        "clean_posts"
      ],
      "metadata": {
        "id": "3RbkcTyrNDcJ",
        "outputId": "37da53ab-c570-486d-fb01-1902371e4a39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-921669650514>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clean_posts['words'] = clean_posts['Clean Body'].apply(extract_words)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Id                                               Body  \\\n",
              "0           5  <p>I've always been interested in machine lear...   \n",
              "1           7  <p>As a researcher and instructor, I'm looking...   \n",
              "2           9  <p>Not sure if this fits the scope of this SE,...   \n",
              "3          10  <p>One book that's freely available is \"The El...   \n",
              "4          14  <p>I am sure data science as will be discussed...   \n",
              "...       ...                                                ...   \n",
              "75722  119962  <p>I am implementing a neural network of arbit...   \n",
              "75723  119963  <p>I am using KNN for a regression task</p>\\n<...   \n",
              "75724  119964  <p>I have developed a small encoding algorithm...   \n",
              "75725  119965  <p>To my understanding, optimizing a model wit...   \n",
              "75726  119966  <p>I'm working with a dataset of cars, contain...   \n",
              "\n",
              "                                              Clean Body  \\\n",
              "0      I've always been interested in machine learnin...   \n",
              "1      As a researcher and instructor, I'm looking fo...   \n",
              "2      Not sure if this fits the scope of this SE, bu...   \n",
              "3      One book that's freely available is \"The Eleme...   \n",
              "4      I am sure data science as will be discussed in...   \n",
              "...                                                  ...   \n",
              "75722  I am implementing a neural network of arbitrar...   \n",
              "75723  I am using KNN for a regression taskIt's like ...   \n",
              "75724  I have developed a small encoding algorithm th...   \n",
              "75725  To my understanding, optimizing a model with k...   \n",
              "75726  I'm working with a dataset of cars, containing...   \n",
              "\n",
              "                                                   words  \n",
              "0      [generating, learning, use, placed, dont, of, ...  \n",
              "1      [relatively, looking, of, in, suitable, a, to,...  \n",
              "2      [it, parameters, its, a, specific, perhaps, th...  \n",
              "3      [book, thinking, learning, although, prof, it,...  \n",
              "4      [in, a, to, need, regards, discussed, few, thi...  \n",
              "...                                                  ...  \n",
              "75722  [depth, each, forwards, think, neural, number,...  \n",
              "75723  [it, sum_of_featur3_normaln, neighbor5, estima...  \n",
              "75724  [seriesi, sense, associated, it, adjacent, its...  \n",
              "75725  [tuning, metrics, a, reconciled, means, perfor...  \n",
              "75726  [dfkm, use, it, its, seems, y_train, metrics, ...  \n",
              "\n",
              "[75727 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddda5863-5f6b-4b79-ac01-98a1c867d6a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Body</th>\n",
              "      <th>Clean Body</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>&lt;p&gt;I've always been interested in machine lear...</td>\n",
              "      <td>I've always been interested in machine learnin...</td>\n",
              "      <td>[generating, learning, use, placed, dont, of, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>&lt;p&gt;As a researcher and instructor, I'm looking...</td>\n",
              "      <td>As a researcher and instructor, I'm looking fo...</td>\n",
              "      <td>[relatively, looking, of, in, suitable, a, to,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>&lt;p&gt;Not sure if this fits the scope of this SE,...</td>\n",
              "      <td>Not sure if this fits the scope of this SE, bu...</td>\n",
              "      <td>[it, parameters, its, a, specific, perhaps, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>&lt;p&gt;One book that's freely available is \"The El...</td>\n",
              "      <td>One book that's freely available is \"The Eleme...</td>\n",
              "      <td>[book, thinking, learning, although, prof, it,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>&lt;p&gt;I am sure data science as will be discussed...</td>\n",
              "      <td>I am sure data science as will be discussed in...</td>\n",
              "      <td>[in, a, to, need, regards, discussed, few, thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75722</th>\n",
              "      <td>119962</td>\n",
              "      <td>&lt;p&gt;I am implementing a neural network of arbit...</td>\n",
              "      <td>I am implementing a neural network of arbitrar...</td>\n",
              "      <td>[depth, each, forwards, think, neural, number,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75723</th>\n",
              "      <td>119963</td>\n",
              "      <td>&lt;p&gt;I am using KNN for a regression task&lt;/p&gt;\\n&lt;...</td>\n",
              "      <td>I am using KNN for a regression taskIt's like ...</td>\n",
              "      <td>[it, sum_of_featur3_normaln, neighbor5, estima...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75724</th>\n",
              "      <td>119964</td>\n",
              "      <td>&lt;p&gt;I have developed a small encoding algorithm...</td>\n",
              "      <td>I have developed a small encoding algorithm th...</td>\n",
              "      <td>[seriesi, sense, associated, it, adjacent, its...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75725</th>\n",
              "      <td>119965</td>\n",
              "      <td>&lt;p&gt;To my understanding, optimizing a model wit...</td>\n",
              "      <td>To my understanding, optimizing a model with k...</td>\n",
              "      <td>[tuning, metrics, a, reconciled, means, perfor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75726</th>\n",
              "      <td>119966</td>\n",
              "      <td>&lt;p&gt;I'm working with a dataset of cars, contain...</td>\n",
              "      <td>I'm working with a dataset of cars, containing...</td>\n",
              "      <td>[dfkm, use, it, its, seems, y_train, metrics, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75727 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddda5863-5f6b-4b79-ac01-98a1c867d6a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ddda5863-5f6b-4b79-ac01-98a1c867d6a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ddda5863-5f6b-4b79-ac01-98a1c867d6a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zipf Law\n",
        "\n",
        "A way of analyzing a corpus is to draw the zipf law"
      ],
      "metadata": {
        "id": "qWfNgdg7ziCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Draw Zipf Law on the Posts Corpus"
      ],
      "metadata": {
        "id": "Yrts6RVNziLk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inverted Index\n",
        "\n",
        "Now, we want to go further on the indexing and build an inverted index. Inverted index is a dictionary where the keys are the words of the vocabulary and the values are the documents containing these words. Reducing the size of the vocabulary is a relevant first step when building an inverted index. Here, we will focus on the creation of the index, we leave you the optimisation steps :)"
      ],
      "metadata": {
        "id": "uOYd2qLpwhHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_index(posts:pd.DataFrame)-> set:\n",
        "  inverted_index = dict()\n",
        "  for i in range(0, len(posts)):\n",
        "    terms = posts['words'].iloc[i]\n",
        "    for term in terms:\n",
        "      if term in inverted_index:\n",
        "        inverted_index[term] = inverted_index[term] + [posts['Id'].iloc[i]]\n",
        "      else: \n",
        "        inverted_index[term] = [posts['Id'].iloc[i]]\n",
        "  return inverted_index"
      ],
      "metadata": {
        "id": "-sCV0Ds21g7J"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inverted_index = create_index(clean_posts.iloc[0:5000])"
      ],
      "metadata": {
        "id": "uCPc3tRMZj9R"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Well Done, you've indexed the dataset! \n",
        "Don't hesitate to save your indexes in txt or pickle file\n",
        "\n",
        "---\n",
        "# Implement the search method\n",
        "\n",
        "A naive method would be to count the number of words in common between the query and each posts. Then to rank the posts you could directly select the post who maximize the number of common words. Let's implement this approach :"
      ],
      "metadata": {
        "id": "q97D2TjBOVZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "JnFkMEU1v2bu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement the word_in_index function \n",
        "# Inputs : a word (str) & a list of words\n",
        "# Output : pandas series of 1 if the word is in the list, else 0\n",
        "\n",
        "def word_in_index(word, word_list_index):\n",
        "  # TODO\n",
        "\n",
        "  # CORR\n",
        "  return int(word in word_list_index)"
      ],
      "metadata": {
        "id": "UZX8J3Vrq7St"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement the function which run through a pandas series and count the number of word in common\n",
        "# Use extract_words method, apply method with word_in_index function\n",
        "# Inputs : the query (str) & pandas series of strings\n",
        "# Output : Pandas series counting the number of common words between the query and each string in word_serie\n",
        "\n",
        "def count_common_words(query, word_serie):\n",
        "  # TODO\n",
        "\n",
        "  # CORR\n",
        "  word_list_query = extract_words(query)\n",
        "  common_word_serie = word_serie.apply(lambda row: np.sum([word_in_index(word, row) for word in word_list_query]))\n",
        "  return common_word_serie\n"
      ],
      "metadata": {
        "id": "GFvxO88LtVi8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# df : (\"words\",  \"Id\") à minima\n",
        "\n",
        "def rank_top_query(query, df, top=5):\n",
        "  # TODO\n",
        "\n",
        "\n",
        "  # CORR\n",
        "  df[\"query_rank\"] = count_common_words(query, df[\"words\"])\n",
        "\n",
        "  return df.sort_values(by=\"query_rank\", ascending=False).head(top)"
      ],
      "metadata": {
        "id": "NHzyXeExNWQq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rank_top_query(query=\"testing the query in python\", df=clean_posts, top=5)"
      ],
      "metadata": {
        "id": "iRdErltStZGv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "68c43d2c-e8f2-4d6a-e758-070d9a3dee2f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-487344b0b33e>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"query_rank\"] = count_common_words(query, df[\"words\"])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Id                                               Body  \\\n",
              "273      309  <p><strong>tl;dr:</strong> They markedly diffe...   \n",
              "178      205  <p>Working on what could often be called \"medi...   \n",
              "35201  54542  <p>I am pretty new to Python and this board so...   \n",
              "46350  71759  <p>I wanted to ask you which coding language I...   \n",
              "51485  80165  <p>I was trying to implement Logistic Regressi...   \n",
              "\n",
              "                                              Clean Body  \\\n",
              "273    tl;dr: They markedly differ in many aspects an...   \n",
              "178    Working on what could often be called \"medium ...   \n",
              "35201  I am pretty new to Python and this board so I ...   \n",
              "46350  I wanted to ask you which coding language I sh...   \n",
              "51485  I was trying to implement Logistic Regression ...   \n",
              "\n",
              "                                                   words  query_rank  \n",
              "273    [efficient, it, its, testing, here, characteri...           5  \n",
              "178    [it, its, testing, rule, apply, a, anywhere, r...           4  \n",
              "35201  [use, it, testing, classificator, please, a, p...           4  \n",
              "46350  [quotyesquot, use, enter, recurring, he, x, cl...           4  \n",
              "51485  [npimport, 3900, 74350233000888215epoch, manda...           4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc7a03c6-b029-43f3-b987-c270ec51d6b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Body</th>\n",
              "      <th>Clean Body</th>\n",
              "      <th>words</th>\n",
              "      <th>query_rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>309</td>\n",
              "      <td>&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; They markedly diffe...</td>\n",
              "      <td>tl;dr: They markedly differ in many aspects an...</td>\n",
              "      <td>[efficient, it, its, testing, here, characteri...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>205</td>\n",
              "      <td>&lt;p&gt;Working on what could often be called \"medi...</td>\n",
              "      <td>Working on what could often be called \"medium ...</td>\n",
              "      <td>[it, its, testing, rule, apply, a, anywhere, r...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35201</th>\n",
              "      <td>54542</td>\n",
              "      <td>&lt;p&gt;I am pretty new to Python and this board so...</td>\n",
              "      <td>I am pretty new to Python and this board so I ...</td>\n",
              "      <td>[use, it, testing, classificator, please, a, p...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46350</th>\n",
              "      <td>71759</td>\n",
              "      <td>&lt;p&gt;I wanted to ask you which coding language I...</td>\n",
              "      <td>I wanted to ask you which coding language I sh...</td>\n",
              "      <td>[quotyesquot, use, enter, recurring, he, x, cl...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51485</th>\n",
              "      <td>80165</td>\n",
              "      <td>&lt;p&gt;I was trying to implement Logistic Regressi...</td>\n",
              "      <td>I was trying to implement Logistic Regression ...</td>\n",
              "      <td>[npimport, 3900, 74350233000888215epoch, manda...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc7a03c6-b029-43f3-b987-c270ec51d6b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc7a03c6-b029-43f3-b987-c270ec51d6b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc7a03c6-b029-43f3-b987-c270ec51d6b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testez plusieurs requêtes et critiquez les résultats obtenus.\n",
        "\n",
        "Quels sont les pros and cons de cette méthodes. Vous l'indiquerez sur le rapport avec vos réflexions pour l'améliorer.\n",
        "\n",
        "Next, you have to implement the first improvements you find in the search method to get most relevant results "
      ],
      "metadata": {
        "id": "JumHiP3txgUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CORR\n",
        "def remove_stop_words(l_txt: list) -> list:\n",
        "  \n",
        "  # Implement without stop words, punctuation, decrease the importance of the ranking with respect to the number of words in the posts\n",
        "\n",
        "  return "
      ],
      "metadata": {
        "id": "ux77Xzftx-kX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boolean Search\n",
        "\n",
        "Thanks to the ttable library, implement a boolean search method"
      ],
      "metadata": {
        "id": "MecCCwzbx8qZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = BooleanExpression('data impl not (science nand learning)')\n",
        "\n",
        "b = BooleanExpression('data AND not science')\n",
        "\n",
        "from functools import reduce\n"
      ],
      "metadata": {
        "id": "oM-cfttdKdXQ"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"data\" in clean_posts.iloc[5591].words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwtTFDk5Xhss",
        "outputId": "43733c4c-cf9a-49f8-de14-ddcb5c6e9e6a"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"science\" in clean_posts.iloc[5591].words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qVjF0MnXS1y",
        "outputId": "afe6c55a-ac49-42d5-caef-3bb627d0d26a"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ZZ[0].iloc[5591]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDi5K8ZKWpMF",
        "outputId": "06769dda-7b34-45b8-f974-913a3fb5052d"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z = []\n",
        "\n",
        "df = pd.DataFrame(b.sat_all())\n",
        "cols = df.columns\n",
        "\n",
        "for r in df.iterrows():\n",
        "  irow, row = r\n",
        "\n",
        "  ZZ = []\n",
        "\n",
        "  for col in cols:\n",
        "    print(col, row[col])\n",
        "    ZZ.append(clean_posts[\"words\"].apply(lambda words:(col in words) == row[col]))\n",
        "\n",
        "  Z.append(reduce(lambda x, y: x&y, ZZ))\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQv_-j_CNud3",
        "outputId": "f25f9638-3b3c-4d2a-9df3-4cbc3cac7242"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data True\n",
            "science False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHve3SGXYl-f",
        "outputId": "9f4f876a-1bf0-403e-db3b-4169ddd85415"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        False\n",
              "1        False\n",
              "2        False\n",
              "3        False\n",
              "4        False\n",
              "         ...  \n",
              "75722    False\n",
              "75723     True\n",
              "75724    False\n",
              "75725     True\n",
              "75726    False\n",
              "Name: words, Length: 75727, dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z[5591]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8drVsQMnYI1K",
        "outputId": "8c835576-078c-42a9-d50b-b60407295c23"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_posts[z]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "SCOTyDMHYyS4",
        "outputId": "bc4fe33a-09f1-4023-f62e-eb5147c8326a"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Id                                               Body  \\\n",
              "6          16  <p>I use <a href=\"http://www.csie.ntu.edu.tw/~...   \n",
              "9          19  <p>Lots of people use the term <em>big data</e...   \n",
              "10         20  <p>We created a social network application for...   \n",
              "11         21  <p>As you rightly note, these days \"big data\" ...   \n",
              "12         22  <p>My data set contains a number of numeric at...   \n",
              "...       ...                                                ...   \n",
              "75707  119946  <p>Good morning everyone.</p>\\n<p>I have the f...   \n",
              "75711  119951  <p>I need to implement classical perceptron al...   \n",
              "75718  119958  <p>I am trying to write a thesis on oil pipe l...   \n",
              "75723  119963  <p>I am using KNN for a regression task</p>\\n<...   \n",
              "75725  119965  <p>To my understanding, optimizing a model wit...   \n",
              "\n",
              "                                              Clean Body  \\\n",
              "6      I use Libsvm to train data and predict classif...   \n",
              "9      Lots of people use the term big data in a rath...   \n",
              "10     We created a social network application for eL...   \n",
              "11     As you rightly note, these days \"big data\" is ...   \n",
              "12     My data set contains a number of numeric attri...   \n",
              "...                                                  ...   \n",
              "75707  Good morning everyone.I have the following dat...   \n",
              "75711  I need to implement classical perceptron algor...   \n",
              "75718  I am trying to write a thesis on oil pipe leak...   \n",
              "75723  I am using KNN for a regression taskIt's like ...   \n",
              "75725  To my understanding, optimizing a model with k...   \n",
              "\n",
              "                                                   words  query_rank  \n",
              "6      [problemlast, liblinear, use, it, mapreduce, l...           1  \n",
              "9      [associated, use, commercial, efficiency, term...           2  \n",
              "10     [each, we, it, its, experimental, other, some,...           2  \n",
              "11     [sense, associated, use, it, its, generous, a,...           2  \n",
              "12     [takes, categoricalattrvalue2, categoricalattr...           1  \n",
              "...                                                  ...         ...  \n",
              "75707  [pandas, 91, 41, 41i, 283, 28, it, 65, 35, 333...           2  \n",
              "75711  [pandas, testing, it, 60k, should, a, mean, 33...           3  \n",
              "75718  [location, parameters, it, should, a, specific...           2  \n",
              "75723  [it, sum_of_featur3_normaln, neighbor5, estima...           2  \n",
              "75725  [tuning, metrics, a, reconciled, means, perfor...           2  \n",
              "\n",
              "[28541 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5466efce-7ca9-436f-883a-aaa391fea2ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Body</th>\n",
              "      <th>Clean Body</th>\n",
              "      <th>words</th>\n",
              "      <th>query_rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>16</td>\n",
              "      <td>&lt;p&gt;I use &lt;a href=\"http://www.csie.ntu.edu.tw/~...</td>\n",
              "      <td>I use Libsvm to train data and predict classif...</td>\n",
              "      <td>[problemlast, liblinear, use, it, mapreduce, l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>19</td>\n",
              "      <td>&lt;p&gt;Lots of people use the term &lt;em&gt;big data&lt;/e...</td>\n",
              "      <td>Lots of people use the term big data in a rath...</td>\n",
              "      <td>[associated, use, commercial, efficiency, term...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>20</td>\n",
              "      <td>&lt;p&gt;We created a social network application for...</td>\n",
              "      <td>We created a social network application for eL...</td>\n",
              "      <td>[each, we, it, its, experimental, other, some,...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>21</td>\n",
              "      <td>&lt;p&gt;As you rightly note, these days \"big data\" ...</td>\n",
              "      <td>As you rightly note, these days \"big data\" is ...</td>\n",
              "      <td>[sense, associated, use, it, its, generous, a,...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>22</td>\n",
              "      <td>&lt;p&gt;My data set contains a number of numeric at...</td>\n",
              "      <td>My data set contains a number of numeric attri...</td>\n",
              "      <td>[takes, categoricalattrvalue2, categoricalattr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75707</th>\n",
              "      <td>119946</td>\n",
              "      <td>&lt;p&gt;Good morning everyone.&lt;/p&gt;\\n&lt;p&gt;I have the f...</td>\n",
              "      <td>Good morning everyone.I have the following dat...</td>\n",
              "      <td>[pandas, 91, 41, 41i, 283, 28, it, 65, 35, 333...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75711</th>\n",
              "      <td>119951</td>\n",
              "      <td>&lt;p&gt;I need to implement classical perceptron al...</td>\n",
              "      <td>I need to implement classical perceptron algor...</td>\n",
              "      <td>[pandas, testing, it, 60k, should, a, mean, 33...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75718</th>\n",
              "      <td>119958</td>\n",
              "      <td>&lt;p&gt;I am trying to write a thesis on oil pipe l...</td>\n",
              "      <td>I am trying to write a thesis on oil pipe leak...</td>\n",
              "      <td>[location, parameters, it, should, a, specific...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75723</th>\n",
              "      <td>119963</td>\n",
              "      <td>&lt;p&gt;I am using KNN for a regression task&lt;/p&gt;\\n&lt;...</td>\n",
              "      <td>I am using KNN for a regression taskIt's like ...</td>\n",
              "      <td>[it, sum_of_featur3_normaln, neighbor5, estima...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75725</th>\n",
              "      <td>119965</td>\n",
              "      <td>&lt;p&gt;To my understanding, optimizing a model wit...</td>\n",
              "      <td>To my understanding, optimizing a model with k...</td>\n",
              "      <td>[tuning, metrics, a, reconciled, means, perfor...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28541 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5466efce-7ca9-436f-883a-aaa391fea2ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5466efce-7ca9-436f-883a-aaa391fea2ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5466efce-7ca9-436f-883a-aaa391fea2ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "post_query = []\n",
        "for z in Z:\n",
        "  post_query.extend(clean_posts[z][\"Id\"].values.tolist())"
      ],
      "metadata": {
        "id": "RqRhiw5BNk5g"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(set(post_query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh5UgJsMWB0-",
        "outputId": "2399fd5d-3417-4988-d725-d411a87c90b5"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[16,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 30,\n",
              " 33,\n",
              " 35,\n",
              " 37,\n",
              " 38,\n",
              " 40,\n",
              " 41,\n",
              " 42,\n",
              " 43,\n",
              " 44,\n",
              " 45,\n",
              " 47,\n",
              " 57,\n",
              " 59,\n",
              " 61,\n",
              " 62,\n",
              " 64,\n",
              " 66,\n",
              " 67,\n",
              " 70,\n",
              " 71,\n",
              " 72,\n",
              " 74,\n",
              " 75,\n",
              " 76,\n",
              " 77,\n",
              " 79,\n",
              " 80,\n",
              " 83,\n",
              " 84,\n",
              " 85,\n",
              " 86,\n",
              " 87,\n",
              " 89,\n",
              " 90,\n",
              " 91,\n",
              " 92,\n",
              " 93,\n",
              " 96,\n",
              " 106,\n",
              " 107,\n",
              " 109,\n",
              " 111,\n",
              " 116,\n",
              " 118,\n",
              " 122,\n",
              " 124,\n",
              " 126,\n",
              " 133,\n",
              " 134,\n",
              " 136,\n",
              " 137,\n",
              " 138,\n",
              " 143,\n",
              " 144,\n",
              " 145,\n",
              " 146,\n",
              " 151,\n",
              " 152,\n",
              " 153,\n",
              " 156,\n",
              " 157,\n",
              " 161,\n",
              " 162,\n",
              " 163,\n",
              " 165,\n",
              " 169,\n",
              " 174,\n",
              " 175,\n",
              " 176,\n",
              " 177,\n",
              " 180,\n",
              " 181,\n",
              " 183,\n",
              " 186,\n",
              " 191,\n",
              " 194,\n",
              " 196,\n",
              " 202,\n",
              " 204,\n",
              " 205,\n",
              " 206,\n",
              " 207,\n",
              " 208,\n",
              " 209,\n",
              " 211,\n",
              " 212,\n",
              " 213,\n",
              " 214,\n",
              " 215,\n",
              " 216,\n",
              " 217,\n",
              " 222,\n",
              " 223,\n",
              " 227,\n",
              " 228,\n",
              " 229,\n",
              " 237,\n",
              " 241,\n",
              " 242,\n",
              " 246,\n",
              " 247,\n",
              " 249,\n",
              " 250,\n",
              " 251,\n",
              " 254,\n",
              " 255,\n",
              " 257,\n",
              " 258,\n",
              " 259,\n",
              " 264,\n",
              " 268,\n",
              " 274,\n",
              " 275,\n",
              " 276,\n",
              " 279,\n",
              " 280,\n",
              " 282,\n",
              " 285,\n",
              " 289,\n",
              " 291,\n",
              " 293,\n",
              " 294,\n",
              " 296,\n",
              " 300,\n",
              " 301,\n",
              " 302,\n",
              " 305,\n",
              " 306,\n",
              " 307,\n",
              " 308,\n",
              " 309,\n",
              " 311,\n",
              " 312,\n",
              " 314,\n",
              " 316,\n",
              " 317,\n",
              " 318,\n",
              " 319,\n",
              " 324,\n",
              " 325,\n",
              " 327,\n",
              " 331,\n",
              " 337,\n",
              " 350,\n",
              " 352,\n",
              " 356,\n",
              " 358,\n",
              " 359,\n",
              " 360,\n",
              " 361,\n",
              " 362,\n",
              " 363,\n",
              " 366,\n",
              " 372,\n",
              " 373,\n",
              " 375,\n",
              " 376,\n",
              " 377,\n",
              " 379,\n",
              " 382,\n",
              " 384,\n",
              " 388,\n",
              " 391,\n",
              " 394,\n",
              " 395,\n",
              " 397,\n",
              " 400,\n",
              " 401,\n",
              " 402,\n",
              " 403,\n",
              " 406,\n",
              " 408,\n",
              " 409,\n",
              " 412,\n",
              " 413,\n",
              " 418,\n",
              " 420,\n",
              " 422,\n",
              " 428,\n",
              " 429,\n",
              " 430,\n",
              " 435,\n",
              " 439,\n",
              " 440,\n",
              " 442,\n",
              " 443,\n",
              " 448,\n",
              " 449,\n",
              " 450,\n",
              " 452,\n",
              " 453,\n",
              " 454,\n",
              " 456,\n",
              " 457,\n",
              " 459,\n",
              " 461,\n",
              " 462,\n",
              " 463,\n",
              " 465,\n",
              " 468,\n",
              " 470,\n",
              " 480,\n",
              " 483,\n",
              " 484,\n",
              " 487,\n",
              " 491,\n",
              " 493,\n",
              " 494,\n",
              " 495,\n",
              " 496,\n",
              " 497,\n",
              " 501,\n",
              " 504,\n",
              " 508,\n",
              " 510,\n",
              " 511,\n",
              " 513,\n",
              " 520,\n",
              " 523,\n",
              " 525,\n",
              " 527,\n",
              " 531,\n",
              " 532,\n",
              " 536,\n",
              " 540,\n",
              " 543,\n",
              " 545,\n",
              " 546,\n",
              " 548,\n",
              " 550,\n",
              " 552,\n",
              " 554,\n",
              " 555,\n",
              " 556,\n",
              " 562,\n",
              " 564,\n",
              " 567,\n",
              " 572,\n",
              " 574,\n",
              " 575,\n",
              " 581,\n",
              " 583,\n",
              " 584,\n",
              " 587,\n",
              " 588,\n",
              " 592,\n",
              " 593,\n",
              " 596,\n",
              " 598,\n",
              " 599,\n",
              " 604,\n",
              " 605,\n",
              " 606,\n",
              " 611,\n",
              " 617,\n",
              " 618,\n",
              " 620,\n",
              " 621,\n",
              " 622,\n",
              " 623,\n",
              " 625,\n",
              " 627,\n",
              " 628,\n",
              " 635,\n",
              " 636,\n",
              " 641,\n",
              " 642,\n",
              " 643,\n",
              " 644,\n",
              " 646,\n",
              " 651,\n",
              " 654,\n",
              " 655,\n",
              " 656,\n",
              " 658,\n",
              " 662,\n",
              " 663,\n",
              " 666,\n",
              " 667,\n",
              " 670,\n",
              " 672,\n",
              " 676,\n",
              " 677,\n",
              " 683,\n",
              " 684,\n",
              " 687,\n",
              " 690,\n",
              " 691,\n",
              " 693,\n",
              " 697,\n",
              " 701,\n",
              " 707,\n",
              " 708,\n",
              " 711,\n",
              " 712,\n",
              " 714,\n",
              " 716,\n",
              " 721,\n",
              " 722,\n",
              " 724,\n",
              " 727,\n",
              " 728,\n",
              " 729,\n",
              " 730,\n",
              " 731,\n",
              " 734,\n",
              " 736,\n",
              " 737,\n",
              " 740,\n",
              " 743,\n",
              " 747,\n",
              " 751,\n",
              " 756,\n",
              " 757,\n",
              " 759,\n",
              " 760,\n",
              " 763,\n",
              " 769,\n",
              " 773,\n",
              " 774,\n",
              " 778,\n",
              " 780,\n",
              " 781,\n",
              " 785,\n",
              " 786,\n",
              " 789,\n",
              " 790,\n",
              " 792,\n",
              " 793,\n",
              " 799,\n",
              " 800,\n",
              " 804,\n",
              " 805,\n",
              " 807,\n",
              " 810,\n",
              " 811,\n",
              " 815,\n",
              " 819,\n",
              " 821,\n",
              " 822,\n",
              " 824,\n",
              " 832,\n",
              " 835,\n",
              " 837,\n",
              " 839,\n",
              " 845,\n",
              " 846,\n",
              " 848,\n",
              " 849,\n",
              " 854,\n",
              " 860,\n",
              " 862,\n",
              " 869,\n",
              " 870,\n",
              " 871,\n",
              " 876,\n",
              " 877,\n",
              " 878,\n",
              " 879,\n",
              " 880,\n",
              " 881,\n",
              " 882,\n",
              " 883,\n",
              " 886,\n",
              " 887,\n",
              " 888,\n",
              " 889,\n",
              " 893,\n",
              " 897,\n",
              " 898,\n",
              " 899,\n",
              " 900,\n",
              " 902,\n",
              " 903,\n",
              " 905,\n",
              " 909,\n",
              " 910,\n",
              " 913,\n",
              " 915,\n",
              " 916,\n",
              " 917,\n",
              " 919,\n",
              " 921,\n",
              " 924,\n",
              " 926,\n",
              " 927,\n",
              " 931,\n",
              " 934,\n",
              " 942,\n",
              " 949,\n",
              " 951,\n",
              " 959,\n",
              " 960,\n",
              " 963,\n",
              " 965,\n",
              " 967,\n",
              " 976,\n",
              " 978,\n",
              " 979,\n",
              " 980,\n",
              " 981,\n",
              " 982,\n",
              " 986,\n",
              " 989,\n",
              " 991,\n",
              " 992,\n",
              " 993,\n",
              " 994,\n",
              " 995,\n",
              " 996,\n",
              " 1000,\n",
              " 1001,\n",
              " 1002,\n",
              " 1003,\n",
              " 1005,\n",
              " 1006,\n",
              " 1007,\n",
              " 1009,\n",
              " 1010,\n",
              " 1015,\n",
              " 1019,\n",
              " 1020,\n",
              " 1022,\n",
              " 1024,\n",
              " 1025,\n",
              " 1026,\n",
              " 1033,\n",
              " 1035,\n",
              " 1036,\n",
              " 1037,\n",
              " 1042,\n",
              " 1047,\n",
              " 1053,\n",
              " 1055,\n",
              " 1056,\n",
              " 1059,\n",
              " 1062,\n",
              " 1063,\n",
              " 1065,\n",
              " 1066,\n",
              " 1067,\n",
              " 1069,\n",
              " 1071,\n",
              " 1074,\n",
              " 1075,\n",
              " 1076,\n",
              " 1077,\n",
              " 1079,\n",
              " 1080,\n",
              " 1081,\n",
              " 1082,\n",
              " 1084,\n",
              " 1092,\n",
              " 1100,\n",
              " 1101,\n",
              " 1103,\n",
              " 1104,\n",
              " 1107,\n",
              " 1108,\n",
              " 1110,\n",
              " 1112,\n",
              " 1113,\n",
              " 1118,\n",
              " 1119,\n",
              " 1121,\n",
              " 1127,\n",
              " 1132,\n",
              " 1135,\n",
              " 1136,\n",
              " 1137,\n",
              " 1144,\n",
              " 1146,\n",
              " 1148,\n",
              " 1154,\n",
              " 1155,\n",
              " 1159,\n",
              " 1164,\n",
              " 1166,\n",
              " 1169,\n",
              " 1172,\n",
              " 1175,\n",
              " 1176,\n",
              " 1178,\n",
              " 1182,\n",
              " 1183,\n",
              " 1188,\n",
              " 1190,\n",
              " 1191,\n",
              " 1192,\n",
              " 1194,\n",
              " 1195,\n",
              " 1196,\n",
              " 1198,\n",
              " 1199,\n",
              " 1200,\n",
              " 1204,\n",
              " 1210,\n",
              " 1213,\n",
              " 1216,\n",
              " 1223,\n",
              " 1225,\n",
              " 1227,\n",
              " 1240,\n",
              " 1244,\n",
              " 1246,\n",
              " 1247,\n",
              " 1248,\n",
              " 1250,\n",
              " 1255,\n",
              " 2256,\n",
              " 2257,\n",
              " 2263,\n",
              " 2265,\n",
              " 2266,\n",
              " 2273,\n",
              " 2276,\n",
              " 2277,\n",
              " 2280,\n",
              " 2285,\n",
              " 2293,\n",
              " 2294,\n",
              " 2296,\n",
              " 2298,\n",
              " 2302,\n",
              " 2304,\n",
              " 2307,\n",
              " 2308,\n",
              " 2311,\n",
              " 2313,\n",
              " 2314,\n",
              " 2315,\n",
              " 2316,\n",
              " 2320,\n",
              " 2328,\n",
              " 2334,\n",
              " 2341,\n",
              " 2343,\n",
              " 2347,\n",
              " 2348,\n",
              " 2352,\n",
              " 2353,\n",
              " 2355,\n",
              " 2358,\n",
              " 2360,\n",
              " 2364,\n",
              " 2365,\n",
              " 2368,\n",
              " 2369,\n",
              " 2370,\n",
              " 2373,\n",
              " 2374,\n",
              " 2376,\n",
              " 2377,\n",
              " 2378,\n",
              " 2379,\n",
              " 2380,\n",
              " 2381,\n",
              " 2383,\n",
              " 2392,\n",
              " 2393,\n",
              " 2394,\n",
              " 2395,\n",
              " 2399,\n",
              " 2410,\n",
              " 2411,\n",
              " 2420,\n",
              " 2421,\n",
              " 2422,\n",
              " 2423,\n",
              " 2426,\n",
              " 2427,\n",
              " 2429,\n",
              " 2432,\n",
              " 2433,\n",
              " 2439,\n",
              " 2442,\n",
              " 2445,\n",
              " 2446,\n",
              " 2448,\n",
              " 2451,\n",
              " 2454,\n",
              " 2456,\n",
              " 2463,\n",
              " 2466,\n",
              " 2468,\n",
              " 2469,\n",
              " 2473,\n",
              " 2474,\n",
              " 2478,\n",
              " 2480,\n",
              " 2483,\n",
              " 2489,\n",
              " 2491,\n",
              " 2493,\n",
              " 2494,\n",
              " 2499,\n",
              " 2500,\n",
              " 2501,\n",
              " 2503,\n",
              " 2504,\n",
              " 2506,\n",
              " 2507,\n",
              " 2514,\n",
              " 2516,\n",
              " 2518,\n",
              " 2521,\n",
              " 2524,\n",
              " 2526,\n",
              " 2530,\n",
              " 2543,\n",
              " 2547,\n",
              " 2549,\n",
              " 2551,\n",
              " 2559,\n",
              " 2564,\n",
              " 2565,\n",
              " 2571,\n",
              " 2572,\n",
              " 2576,\n",
              " 2578,\n",
              " 2581,\n",
              " 2584,\n",
              " 2585,\n",
              " 2588,\n",
              " 2589,\n",
              " 2594,\n",
              " 2596,\n",
              " 2597,\n",
              " 2598,\n",
              " 2599,\n",
              " 2607,\n",
              " 2608,\n",
              " 2612,\n",
              " 2616,\n",
              " 2619,\n",
              " 2620,\n",
              " 2621,\n",
              " 2625,\n",
              " 2627,\n",
              " 2632,\n",
              " 2640,\n",
              " 2649,\n",
              " 2654,\n",
              " 2658,\n",
              " 2660,\n",
              " 2661,\n",
              " 2663,\n",
              " 2668,\n",
              " 2675,\n",
              " 2677,\n",
              " 2678,\n",
              " 2682,\n",
              " 3688,\n",
              " 3691,\n",
              " 3692,\n",
              " 3693,\n",
              " 3696,\n",
              " 3697,\n",
              " 3698,\n",
              " 3699,\n",
              " 3705,\n",
              " 3708,\n",
              " 3711,\n",
              " 3713,\n",
              " 3718,\n",
              " 3719,\n",
              " 3720,\n",
              " 3723,\n",
              " 3726,\n",
              " 3730,\n",
              " 3732,\n",
              " 3735,\n",
              " 3738,\n",
              " 3740,\n",
              " 3741,\n",
              " 3742,\n",
              " 3746,\n",
              " 3747,\n",
              " 3752,\n",
              " 3753,\n",
              " 3754,\n",
              " 3757,\n",
              " 3758,\n",
              " 3761,\n",
              " 3763,\n",
              " 3766,\n",
              " 3770,\n",
              " 3771,\n",
              " 3772,\n",
              " 3777,\n",
              " 3779,\n",
              " 3785,\n",
              " 3786,\n",
              " 3787,\n",
              " 3788,\n",
              " 3790,\n",
              " 3791,\n",
              " 3795,\n",
              " 3797,\n",
              " 3798,\n",
              " 3800,\n",
              " 3801,\n",
              " 3802,\n",
              " 3804,\n",
              " 3811,\n",
              " 3812,\n",
              " 3813,\n",
              " 3814,\n",
              " 3815,\n",
              " 3816,\n",
              " 3817,\n",
              " 3819,\n",
              " 3820,\n",
              " 3825,\n",
              " 3826,\n",
              " 3827,\n",
              " 4830,\n",
              " 4834,\n",
              " 4839,\n",
              " 4842,\n",
              " 4843,\n",
              " 4847,\n",
              " 4851,\n",
              " 4852,\n",
              " 4855,\n",
              " 4859,\n",
              " 4860,\n",
              " 4862,\n",
              " 4863,\n",
              " 4864,\n",
              " 4866,\n",
              " 4876,\n",
              " 4878,\n",
              " 4883,\n",
              " 4887,\n",
              " 4888,\n",
              " 4894,\n",
              " 4895,\n",
              " 4896,\n",
              " 4898,\n",
              " 4899,\n",
              " 4901,\n",
              " 4904,\n",
              " 4905,\n",
              " 4910,\n",
              " 4912,\n",
              " 4914,\n",
              " 4915,\n",
              " 4917,\n",
              " 4920,\n",
              " 4924,\n",
              " 4935,\n",
              " 4936,\n",
              " 4937,\n",
              " 4938,\n",
              " 4941,\n",
              " 4942,\n",
              " 4945,\n",
              " 4946,\n",
              " 4948,\n",
              " 4949,\n",
              " 4950,\n",
              " 4952,\n",
              " 4955,\n",
              " 4957,\n",
              " 4958,\n",
              " 4961,\n",
              " 4969,\n",
              " 4971,\n",
              " 4972,\n",
              " 4979,\n",
              " 4980,\n",
              " 4982,\n",
              " 4984,\n",
              " 4985,\n",
              " 4986,\n",
              " 4988,\n",
              " 4989,\n",
              " 4991,\n",
              " 4992,\n",
              " 4993,\n",
              " 4997,\n",
              " 5000,\n",
              " 5001,\n",
              " 5002,\n",
              " 5006,\n",
              " 5008,\n",
              " 5011,\n",
              " 5013,\n",
              " 5015,\n",
              " 5016,\n",
              " 5019,\n",
              " 5021,\n",
              " 5022,\n",
              " 5029,\n",
              " 5037,\n",
              " 5040,\n",
              " 5043,\n",
              " 5045,\n",
              " 5047,\n",
              " 5048,\n",
              " 5049,\n",
              " 5055,\n",
              " 5061,\n",
              " 5062,\n",
              " 5074,\n",
              " 5077,\n",
              " 5079,\n",
              " 5080,\n",
              " 5085,\n",
              " 5086,\n",
              " 5091,\n",
              " 5092,\n",
              " 5093,\n",
              " 5096,\n",
              " 5097,\n",
              " 5099,\n",
              " 5101,\n",
              " 5103,\n",
              " 5104,\n",
              " 5107,\n",
              " 5109,\n",
              " 5114,\n",
              " 5120,\n",
              " 5122,\n",
              " 5129,\n",
              " 5133,\n",
              " 5135,\n",
              " 5137,\n",
              " 5140,\n",
              " 5141,\n",
              " 5149,\n",
              " 5152,\n",
              " 5153,\n",
              " 5156,\n",
              " 5161,\n",
              " 5162,\n",
              " 5169,\n",
              " 5172,\n",
              " 5173,\n",
              " 5179,\n",
              " 5185,\n",
              " 5196,\n",
              " 5197,\n",
              " 5198,\n",
              " 5200,\n",
              " 5202,\n",
              " 5204,\n",
              " 5205,\n",
              " 5208,\n",
              " 5212,\n",
              " 5214,\n",
              " 5215,\n",
              " 5220,\n",
              " 5221,\n",
              " 5222,\n",
              " 5223,\n",
              " 5224,\n",
              " 5227,\n",
              " 5229,\n",
              " 5231,\n",
              " 5232,\n",
              " 5237,\n",
              " 5239,\n",
              " 5241,\n",
              " 5244,\n",
              " 5248,\n",
              " 5249,\n",
              " 5252,\n",
              " 5253,\n",
              " 5256,\n",
              " 5259,\n",
              " 5261,\n",
              " 5267,\n",
              " 5268,\n",
              " 5277,\n",
              " 5279,\n",
              " 5281,\n",
              " 5284,\n",
              " 5285,\n",
              " 5291,\n",
              " 5295,\n",
              " 5299,\n",
              " 5302,\n",
              " 5303,\n",
              " 5305,\n",
              " 5314,\n",
              " 5319,\n",
              " 5320,\n",
              " 5322,\n",
              " 5326,\n",
              " 5330,\n",
              " 5334,\n",
              " 5336,\n",
              " 5338,\n",
              " 5347,\n",
              " 5349,\n",
              " 5359,\n",
              " 5361,\n",
              " 5365,\n",
              " 5367,\n",
              " 5370,\n",
              " 5376,\n",
              " 5379,\n",
              " 5380,\n",
              " 5385,\n",
              " 5386,\n",
              " 5387,\n",
              " 5388,\n",
              " 5389,\n",
              " 5394,\n",
              " 5395,\n",
              " 5397,\n",
              " 5400,\n",
              " 5401,\n",
              " 5403,\n",
              " 5408,\n",
              " 5409,\n",
              " 5410,\n",
              " 5414,\n",
              " 5418,\n",
              " 5419,\n",
              " 5427,\n",
              " 5429,\n",
              " 5430,\n",
              " 5436,\n",
              " 5437,\n",
              " 5443,\n",
              " 5448,\n",
              " 5450,\n",
              " 5460,\n",
              " 5469,\n",
              " 5473,\n",
              " 5479,\n",
              " 5481,\n",
              " 5489,\n",
              " 5490,\n",
              " 5502,\n",
              " 5503,\n",
              " 5504,\n",
              " 5505,\n",
              " 5508,\n",
              " 5512,\n",
              " 5513,\n",
              " 5515,\n",
              " 5519,\n",
              " 5521,\n",
              " 5524,\n",
              " 5527,\n",
              " 5530,\n",
              " 5533,\n",
              " 5534,\n",
              " 5537,\n",
              " 5538,\n",
              " 5543,\n",
              " 5544,\n",
              " 5548,\n",
              " 5550,\n",
              " 5551,\n",
              " 5553,\n",
              " 5561,\n",
              " 5562,\n",
              " 5563,\n",
              " 5573,\n",
              " 5574,\n",
              " 5582,\n",
              " 5585,\n",
              " 5586,\n",
              " 5588,\n",
              " 5591,\n",
              " 5595,\n",
              " 5596,\n",
              " 5603,\n",
              " 5606,\n",
              " 5607,\n",
              " 5611,\n",
              " 5612,\n",
              " 5618,\n",
              " 5627,\n",
              " 5628,\n",
              " 5630,\n",
              " 5631,\n",
              " 5634,\n",
              " 5635,\n",
              " 5636,\n",
              " 5642,\n",
              " 5644,\n",
              " 5645,\n",
              " 5648,\n",
              " 5659,\n",
              " 5661,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"data\" in clean_posts.iloc[5591][\"words\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5JTNdIrVdH9",
        "outputId": "d23ee4b1-7cce-4987-f759-4b3a09bea830"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Probabilistic search\n",
        "\n",
        "Implement the MIB or BM25 method of searching"
      ],
      "metadata": {
        "id": "N4vFldsAycpB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bCxjyrldyhUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the naive method with your improvements and the boolean and probabilistic search. (report)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x9m_LFo_yog2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the Search\n",
        "\n",
        "Now you implement multiple search methods and you're able to improve it. You have to define metric to compare it objectively.\n",
        "\n",
        "We ask you to implement NDCG (Normalized Discounted Cumulative Gain) from few queries we implement on a dozen of post. We already defined the values of relevance judgement in the csv file : . The final score will be the mean quadratic error of the queries.\n",
        "\n",
        "The scaling value (Z) must be scale to 1.\n",
        "\n",
        "You will have to criticize this metric and your result in the report. Then you will have to propose some improvements. \n",
        "\n",
        "Thereafter in this week, you will have to compare your different search engines."
      ],
      "metadata": {
        "id": "arfKMWtLyyxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FAKE EXAMPLE\n",
        "\n",
        "df = pd.DataFrame(columns=[\"postId\", \"query\", \"query_output\"], data=[[1, 3, 1], [2, 1, 2], [3, None, 3], [4, 2, 4]])\n",
        "# df = pd.DataFrame(columns=[\"postId\", \"query\", \"query_output\"], data=[[1, 3, 3], [2, 1, 1], [3, None, 4], [4, 2, 2]])\n",
        "\n",
        "# \n",
        "\n",
        "ndgc = []\n",
        "\n",
        "# For a query\n",
        "\n",
        "def calculate_ndgc(df, query_col=\"query\", output_col=\"query_output\"):\n",
        "  nb_post_relevant = df[\"query\"].count()\n",
        "  v = 0\n",
        "  df = df.sort_values(by=query_col)\n",
        "  for irow, row in enumerate(df[output_col]):\n",
        "    if irow < nb_post_relevant:\n",
        "      v += (2**(row) - 1) / math.log(irow + 1 + 1, 2)\n",
        "  return v\n",
        "\n",
        "# Squared Error between best ndgc and ndgc of the search engine\n",
        "mean_squared_error([calculate_ndgc(df=df, query_col=q, output_col=q+\"_output\") for q in ['query']],\n",
        "                   [calculate_ndgc(df=df, query_col=q, output_col=q) for q in ['query']]\n",
        "                          )"
      ],
      "metadata": {
        "id": "FVxld-Ujy0nN",
        "outputId": "8626044e-eda8-41a5-b49d-7ab1a3703417",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43.18010488189557"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[calculate_ndgc(df=df, query_col=q, output_col=q+\"_output\") for q in ['query']], [calculate_ndgc(df=df, query_col=q, output_col=q) for q in ['query']]"
      ],
      "metadata": {
        "id": "BBeZyIY9YALO",
        "outputId": "b4e60f61-1b07-43af-e117-fe05049aefac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([6.392789260714372], [6.392789260714372])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bjsmWtKMYA7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XPaPk_VlYRMA",
        "outputId": "5277366b-1fcb-4e0b-9185-ec482ba05ffb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14.9165082750002"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "math.avg"
      ],
      "metadata": {
        "id": "cc-d9Wb0ZUnr",
        "outputId": "9c7611ce-2525-4d8c-fa75-6ea4d4127b07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-2dbb0c8845c9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'math' has no attribute 'avg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ndgc"
      ],
      "metadata": {
        "id": "do3XC7kRarLZ",
        "outputId": "666f5e7b-b4da-4aa8-a071-d5fff580d364",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6.392789260714372]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HT6bor2Pax73"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}